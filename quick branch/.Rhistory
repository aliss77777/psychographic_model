setwd('/Users/alexander.liss/Volumes/possibleshare')
setwd('/NYC-0559/possibleshare/private')
setwd('~/NYC-0559/possibleshare/private')
library(lavaan)
library(semTools)
library(semPlot)
#specify the structural model
piesModel <- " General =~ i1 + i2 + i3
Feature =~ i4 + i5 + i6 + i7
Image =~ i8 + i9 + i10 + i11
PIES =~ General + Feature + Image"
piesDataModel <- " General =~ 0.9*i1 + 0.7*i2 * 0.5*i3
Feature =~ 0.3*i3 + 0.7*i4 + 0.9*i5 + 0.5*i6 + 0.9*i7
Image =~ 0.2*i3 + 0.8*i8 + 0.9*i9 + 0.8*i10 + 0.7*i11
PIES =~ 0.7*General + 0.8*Feature + 0.8*Image"
set.seed(10001)
library(lavaan)
library(semTools)
library(semPlot)
#specify the structural model
piesModel <- " General =~ i1 + i2 + i3
Feature =~ i4 + i5 + i6 + i7
Image =~ i8 + i9 + i10 + i11
PIES =~ General + Feature + Image"
#simulate the data frame
piesDataModel <- " General =~ 0.9*i1 + 0.7*i2 * 0.5*i3
Feature =~ 0.3*i3 + 0.7*i4 + 0.9*i5 + 0.5*i6 + 0.9*i7
Image =~ 0.2*i3 + 0.8*i8 + 0.9*i9 + 0.8*i10 + 0.7*i11
PIES =~ 0.7*General + 0.8*Feature + 0.8*Image"
set.seed(10001)
piesSimData.norm <- simulateData(piesDataModel, sample.nobs = 3600)
print(head(piesSimData.norm), digits = 2)
piesSimData <- data.frame(lapply(piesSimData.norm,
function(x){cut (x, breaks = 7, labels = FALSE)}))
#so, apparently you can use Lapply even though this object is not a list. WOW~!
#detour - i need to understand what that line of code just did
cut(100, breaks = 10, labels = FALSE)
??cut
Z <- stats::rnorm(10000)
table(cut(Z, breaks = -6:6))
hist(Z)
length(Z)
??lapply
x <- list(a = 1:10)
x
lapply(x, mean)
derp <- cut(Z, breaks = 5, labels = FALSE)
hist(derp)
??apply
#resuming the lesson
library(car)
some(piesSimData)
library(psych)
describe(piesSimData)
library(RColorBrewer)
scatterplotMatrix(piesSimData[, c(1, 2, 4, 5, 8, 9)], diagonal = "histogram",
col = brewer.pal(3, "Paired"), ellipse=TRUE)
install.packages("semPlot")
library(semPlot)
#let's do an exploratory factor analysis before we dive in
factanal(piesSimData, factors = 3)
pies.fit <- cfa(piesModel, data = piesSimData)
View(piesSimData.norm)
View(piesSimData.norm)
library(lavaan)
library(semTools)
install.packages("semPlot")
#install.packages("semPlot")
library(semPlot)
#specify the structural model
piesModel <- " General =~ i1 + i2 + i3
Feature =~ i4 + i5 + i6 + i7
Image =~ i8 + i9 + i10 + i11
PIES =~ General + Feature + Image"
#simulate the data frame
piesDataModel <- " General =~ 0.9*i1 + 0.7*i2 * 0.5*i3
Feature =~ 0.3*i3 + 0.7*i4 + 0.9*i5 + 0.5*i6 + 0.9*i7
Image =~ 0.2*i3 + 0.8*i8 + 0.9*i9 + 0.8*i10 + 0.7*i11
PIES =~ 0.7*General + 0.8*Feature + 0.8*Image"
set.seed(10001)
piesSimData.norm <- simulateData(piesDataModel, sample.nobs = 3600)
View(piesSimData.norm)
piesDataModel <- " General =~ 0.9*i1 + 1*i2 * 0.5*i3
Feature =~ 0.3*i3 + 0.7*i4 + 0.9*i5 + 0.5*i6 + 0.9*i7
Image =~ 0.2*i3 + 0.8*i8 + 0.9*i9 + 0.8*i10 + 0.7*i11
PIES =~ 0.7*General + 0.8*Feature + 0.8*Image"
set.seed(10001)
piesSimData.norm <- simulateData(piesDataModel, sample.nobs = 3600)
print(head(piesSimData.norm), digits = 2)
piesDataModel <- " General =~ 0.9*i1 + 0.7*i2 * 0.5*i3
Feature =~ 0.3*i3 + 0.7*i4 + 0.9*i5 + 0.5*i6 + 0.9*i7
Image =~ 0.2*i3 + 0.8*i8 + 0.9*i9 + 0.8*i10 + 0.7*i11
PIES =~ 0.7*General + 0.8*Feature + 0.8*Image"
set.seed(10001)
piesSimData.norm <- simulateData(piesDataModel, sample.nobs = 3600)
print(head(piesSimData.norm), digits = 2)
piesModel <- " General =~ i1 + i2 + i3
Feature =~ i4 + i5 + i6 + i7
Image =~ i8 + i9 + i10 + i11
PIES =~ General + Feature + Image"
piesDataModel <- " General =~ 0.9*i1 + 0.7*i2 * 0.5*i3
Feature =~ 0.3*i3 + 0.7*i4 + 0.9*i5 + 0.5*i6 + 0.9*i7
Image =~ 0.2*i3 + 0.8*i8 + 0.9*i9 + 0.8*i10 + 0.7*i11
PIES =~ 0.7*General + 0.8*Feature + 0.8*Image"
set.seed(10001)
piesSimData.norm <- simulateData(piesDataModel, sample.nobs = 3600)
print(head(piesSimData.norm), digits = 2)
library(lavaan)
library(semTools)
#install.packages("semPlot")
library(semPlot)
#specify the structural model
piesModel <- " General =~ i1 + i2 + i3
Feature =~ i4 + i5 + i6 + i7
Image =~ i8 + i9 + i10 + i11
PIES =~ General + Feature + Image"
#simulate the data frame
piesDataModel <- " General =~ 0.9*i1 + 0.7*i2 + 0.5*i3
Feature =~ 0.3*i3 + 0.7*i4 + 0.9*i5 + 0.5*i6 + 0.9*i7
Image =~ 0.2*i3 + 0.8*i8 + 0.9*i9 + 0.8*i10 + 0.7*i11
PIES =~ 0.7*General + 0.8*Feature + 0.8*Image"
set.seed(10001)
piesSimData.norm <- simulateData(piesDataModel, sample.nobs = 3600)
print(head(piesSimData.norm), digits = 2)
piesSimData <- data.frame(lapply(piesSimData.norm,
function(x){cut (x, breaks = 7, labels = FALSE)}))
#so, apparently you can use Lapply even though this object is not a list. WOW~!
#detour - i need to understand what that line of code just did
cut(100, breaks = 10, labels = FALSE)
??cut
Z <- stats::rnorm(10000)
table(cut(Z, breaks = -6:6))
hist(Z)
length(Z)
??lapply
x <- list(a = 1:10)
x
lapply(x, mean)
derp <- cut(Z, breaks = 5, labels = FALSE)
hist(derp)
??apply
#resuming the lesson
library(car)
some(piesSimData)
library(psych)
describe(piesSimData)
library(RColorBrewer)
scatterplotMatrix(piesSimData[, c(1, 2, 4, 5, 8, 9)], diagonal = "histogram",
col = brewer.pal(3, "Paired"), ellipse=TRUE)
#let's do an exploratory factor analysis before we dive in
factanal(piesSimData, factors = 3)
pies.fit <- cfa(piesModel, data = piesSimData)
scatterplotMatrix(piesSimData[, c(1, 2, 4, 5, 8, 9)], diag = "histogram",
col = brewer.pal(3, "Paired"), ellipse=TRUE)
## setup
library(googleAnalyticsR)
## authenticate, get code from browser pop-up window
ga_auth()
## get your accounts
account_list <- ga_account_list()
#create list of account ID's you want, in this case 132015390
## account_list will have a column called "viewId"
account_list$viewId
## View account_list and pick the viewId you want to extract data from
ga_id <- 132015390
test <- google_analytics(ga_id,
date_range = c("2017-01-01", "2017-01-30"),
metrics = c("ga:sessions", "ga:users", "ga:newUsers", "ga:pageviews", "ga:avgSessionDuration"),
dimensions = "date")
test <- cbind(test, ga_id)
write.csv(account_list, "Fresenius GA properties.csv", row.names = FALSE)
save.image("~/Egnyte/Private/alexander.liss/0_MarSci Practice/Fresenius/GA script v1.RData")
library(WatsonR)
watson.keys.display()
watson.keys.enter()
load("/Users/alexander.liss/Egnyte/Private/alexander.liss/2_clients/VW/brief/modeling/modeling WIP.Rdata")
table(unique(RF.data$VehicleOwned))
table(unique(mydata_withFA_updated$Type))
table((mydata_withFA_updated$Type))
install.packages('IRkernel')
IRkernel::installspec()
IRkernel::installspec(user = FALSE)
library(tidyverse)
library(readxl)
options(digits = 2)
set.seed(42) # for reproducible results
# 1.  Applying Psychographic Model  ------------------------------------------------------
library(caret)
?len
library(utils)
test <- expand.grid(height = seq(60, 80, 5), weight = seq(100, 300, 50),
sex = c("Male","Female"))
View(test)
library(jsonlite)
library(rlist)
library(bigrquery)
get_access_cred()
project_id <- "centrica-pfe"
sql_string <- "SELECT * WIN.digital_market_geo LIMIT 5"
query_exec(sql_string, project = project_id, use_legacy_sql = FALSE)
sql_string <- "SELECT * FROM WIN.digital_market_geo LIMIT 5"
query_exec(sql_string, project = project_id, use_legacy_sql = FALSE)
updateR
install_github('andreacirilloac/updateR')
library(updateR)
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
updateR()
updateR(admin_password = 'kataBASIS8[]')
install.packages(as.vector(needed_packages))
library(tidyverse)
installed.packages()
update.packages(checkBuilt=TRUE)
update.packages()
update.packages(checkBuilt=TRUE)
library(tidyverse)
# load data file with pre-trained model
setwd("~/Egnyte/Private/alexander.liss/0_MarSci_Practice/1_CodingTutorials/psychographic_model/quick branch")
load("~/Egnyte/Private/alexander.liss/0_MarSci_Practice/1_CodingTutorials/psychographic_model/quick branch/psychgraphic_model.RData")
setwd("~/Egnyte/Private/alexander.liss/0_MarSci_Practice/1_CodingTutorials/psychographic_model/quick branch")
# load data file with pre-trained model
setwd("~/Egnyte/Private/alexander.liss/0_MarSci_Practice/1_CodingTutorials/psychographic_model/quick branch")
#load("~/Egnyte/Private/alexander.liss/0_MarSci_Practice/1_CodingTutorials/psychographic_model/quick branch/psychgraphic_model.RData")
load("psychgraphic_model.RData")
library(tidyverse)
options(digits = 2)
set.seed(42) # for reproducible results
# 1.  Applying Psychographic Model  ------------------------------------------------------
library(caret) # you use the model_list object in the data file to apply the propensities
#load this data file when starting from the beginning
new.data.full <- read.csv("sample data with GUID.csv")
#new.data.full <- read.csv("sample data with GUID and kantar.csv")
features.for.predictive.model <- new.data.full[2:63] # removing unnecessary columns (velo.id) , brand flown, for predictive model
for (i in 1:length(modelnames)){
temp_column <- data.frame(predict(model_list[i][[1]], newdata = features.for.predictive.model))
names(temp_column) <- modelnames[i]
features.for.predictive.model <- cbind(features.for.predictive.model, temp_column)
rm(temp_column)
}
data_with_psychographic_propensities <- cbind(new.data.full[c(1,66)], features.for.predictive.model) #this adds back the info that got removed - Brand Flown (target variable)
#write.csv(data_with_psychographic_propensities, "data.with.psychographic.propensities.csv", row.names = FALSE)
# 2. Applying Logistics Regression across brands --------------------------
library(effects)
# quick exploration plot of vehicle ownership
barplot(table(data_with_psychographic_propensities$BrandFlown))
# selecting just a few columns for modeling
modeling.data <- data_with_psychographic_propensities[c(2,65:74)]
unique(modeling.data$BrandFlown)
# Fit a logistic regression model for Emirates ownership
modeling.data$BrandFlown <- as.factor(modeling.data$BrandFlown)
fit_glm <- glm(BrandFlown == "Emirates.Airline.Traveler" ~ ., family = "binomial", data = modeling.data)
summary(fit_glm)
glm_predictions <- predict(fit_glm, type="response")
modeling.data$Probability.of.Flying.Emirates <- glm_predictions
#examining variable importance for the GLM model
GLM_scores <- data.frame(varImp(fit_glm))
GLM_scores$Propensity <- row.names(GLM_scores)
GLM_labels <- row.names(GLM_scores)
row.names(GLM_scores) <- NULL
barplot(GLM_scores$Overall, names.arg = GLM_labels)
# effects plot to see the relative importance of each predictor to being an Emirates flyer
#https://www.r-bloggers.com/5-alternatives-to-the-default-r-outputs-for-glms-and-linear-models/
effects_plot <- allEffects(fit_glm)
plot(effects_plot, col = 4, ylab = "Probability of Flying Emirates", type = "response", main = " ")
# save this to the drive using the options you prefer
# # now that was a satisfying result! let's export summary statistics and a clean data frame
write.csv(fit_glm$coefficients, "Emirates Attitudinal Predictive Model Coefficients Summary.csv", row.names = FALSE)
write.csv(GLM_scores, "Emirates Predictive Model Variable Importance Scores.csv", row.names = FALSE)
data_with_psychographic_propensities$Probability.of.Flying.Emirates <- modeling.data$Probability.of.Flying.Emirates
write.csv(data_with_psychographic_propensities, "Data with updated FA & Predicted Emirates Propensity.csv", row.names = FALSE)
# 3. creating indexed importance scores for each brand --------------------
# this step repeats the model above but for all brands
# allowing you to create really cool scatterplots comparing the propensities for each brand
modeling.data$BrandFlown <- as.factor(modeling.data$BrandFlown)
# create the list of glm models for each brand and unindexed coefficients
brands <- unique(modeling.data$BrandFlown)
models_each_brand <- vector("list",length(brands))
names(models_each_brand) <- brands
importance_scores_each_brand <- data.frame(matrix(0, ncol = 10, nrow = 0)) # of columns is equal to # of predictors in the model (10)
for (i in 1:length(brands)){
temp_model <- glm(BrandFlown == brands[i] ~ ., data = modeling.data[-12], family = "binomial")
models_each_brand[i]<- list(temp_model)
temp_scores <- t(varImp(models_each_brand[[i]]))
#importance_scores_each_brand[1,] <- temp_scores
importance_scores_each_brand <- rbind(importance_scores_each_brand, temp_scores)
#
#models <- append(list, temp_model)
}
importance_scores_each_brand$Brand <- brands
importance_scores_each_brand <- data.frame(importance_scores_each_brand[c(11,1:10)], row.names = NULL)
write.csv(importance_scores_each_brand, "importance_scores_each_brand.csv", row.names = FALSE)
# now index the scores and create new columns
importances_column_means <- colMeans(importance_scores_each_brand[-1])
coefficient_names <- names(importance_scores_each_brand[-1])
coefficient_names_indexed <- paste(coefficient_names, "_index", sep = "") # creating the col names for the new data frame of indexed columns
importance_scores_index_each_brand <- data.frame(matrix(0, ncol = 10, nrow = 0)) # of columns is equal to # of predictors in the model (10)
colnames(importance_scores_index_each_brand) <- coefficient_names_indexed
for (i in 1:nrow(importance_scores_each_brand)){
for (j in 1:length(importance_scores_each_brand[-1])){
# this populats each cell of a new data frame with an indexed score of the importance of that variable (relative to the other brands)
importance_scores_index_each_brand[i,j] <- (importance_scores_each_brand[i,j+1] / importances_column_means[j]) * 100
# j+1 on the operation above because the first column of importance_scores_each_brand is a factor, need to start with the 2nd column
}
}
importance_scores_index_each_brand <- bind_cols(importance_scores_each_brand[1], importance_scores_index_each_brand)
# now gather everything into a clean file for tableau exploration
backup <- importance_scores_each_brand   # lol just in case something gets messed up
importance_scores_each_brand <- importance_scores_each_brand %>% #gather into a tidy layout
gather(key = "Psychographic Dimension", value = "Unscaled_Coefficient", 2:11)
backup <- importance_scores_index_each_brand
importance_scores_index_each_brand <- importance_scores_index_each_brand %>% #gather into a tidy layout
gather(key = "Psychographic Dimension", value = "Indexed_Coefficient", 2:11)
# adding one more column - the mean propensity scores for each brand
propensity_by_brand <- data_with_psychographic_propensities %>%
group_by(BrandFlown) %>%
select(BrandFlown, 65:74) %>%
summarise_all(funs(mean(., na.rm = TRUE))) %>%
gather(key = Propensity, value = Mean_Propensity, 2:11)
final_coefficients_output <- bind_cols(importance_scores_each_brand, importance_scores_index_each_brand[3], propensity_by_brand[3])
write.csv(final_coefficients_output, "Coefficients by Brand for Analysis.csv", row.names = FALSE)
# 4. visualization --------------------------------------------------------
# dropping brands with low base size
data_for_visualization <- data_with_psychographic_propensities %>%
group_by(BrandFlown) %>%
add_count(BrandFlown) %>%
filter(n > 50)
# we'll use this later
filtered_brand_list <- as.character(unique(data_for_visualization$BrandFlown))
# 4.1 creating a scatterplot to show how Emirates differentiates from other brands based on top propensities
# creating a ranking of top two/three propensities for our brand
GLM_scores <- arrange(GLM_scores, -Overall)
propensity_one <- GLM_scores[1,2]
propensity_two <- GLM_scores[2,2]
propensity_three <- GLM_scores[3,2]
# scatter plot of how Emirates compared to other brands according to our key propensities
data_for_visualization %>%
group_by(BrandFlown) %>%
select(propensity_three, propensity_two) %>%
summarise_all(funs(mean(., na.rm = TRUE))) %>%
ggplot(aes(x=Spirituality.and.Wellness,
y=Stability_1,
color=BrandFlown)) +
geom_point() + scale_y_reverse() + scale_x_reverse() #reversing y axis for Emirates specifically
final_coefficients_output$`Psychographic Dimension` <- as.factor(final_coefficients_output$`Psychographic Dimension`)
# the massive matrix of key ways to message to all brands for DCO
final_coefficients_output %>%
filter(Brand %in% filtered_brand_list) %>%
group_by(Brand, `Psychographic Dimension`) %>%
select(Mean_Propensity, Indexed_Coefficient) %>%
ggplot(aes(x=Mean_Propensity,
y=Indexed_Coefficient,
color=Brand, shape=`Psychographic Dimension`)) +
scale_shape_manual(values=1:nlevels(final_coefficients_output$`Psychographic Dimension`)) +
geom_point()
